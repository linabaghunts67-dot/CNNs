# -*- coding: utf-8 -*-
"""Homework 6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yZSOcYrAQUENLgCST6whL5tVsTMu_a-L

# Homework: The Transfer Learning Challenge üêù vs üêú
## The Challenge:
You are given a very small dataset (~120 images) of Ants and Bees.
Your goal is to build a classifier that distinguishes between them.

## The Catch:
If you train a CNN from scratch on this small dataset, you will likely struggle to get past 60-70% accuracy (Overfitting).
To get a high score (>90%), you MUST use Transfer Learning (Fine-Tuning a ResNet).

Tasks:
1. Setup DataLoaders with Data Augmentation.
2. Load a Pre-trained ResNet-18.
3. Modify the final layer to output 2 classes.
4. Train the model and beat the baseline!
"""

import os
import zipfile
import requests

# Download the Hymenoptera Dataset (Standard PyTorch Tutorial Dataset)
# This dataset contains roughly 120 training images each for ants and bees.
data_url = "https://download.pytorch.org/tutorial/hymenoptera_data.zip"
data_path = "./hymenoptera_data"

if not os.path.exists(data_path):
    print("Downloading dataset...")
    r = requests.get(data_url)
    with open("data.zip", "wb") as f:
        f.write(r.content)

    print("Unzipping...")
    with zipfile.ZipFile("data.zip", "r") as zip_ref:
        zip_ref.extractall(".")
    print("Done!")
else:
    print("Dataset already exists.")

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import numpy as np
import time
import os

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# TODO: Define your transforms
# Hint: You MUST resize images to 224x224 for ResNet.
# Hint: For 'train', use RandomHorizontalFlip and RandomResizedCrop for augmentation.
# Hint: For 'val', just Resize and CenterCrop.
data_transforms = {
    'train': transforms.Compose([
        # --- YOUR CODE HERE ---
    ]),
    'val': transforms.Compose([
        # --- YOUR CODE HERE ---
    ]),
}

# Load the datasets
data_dir = 'hymenoptera_data'
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in ['train', 'val']}

dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
                                             shuffle=True, num_workers=2)
               for x in ['train', 'val']}

dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes

print(f"Classes: {class_names}")
print(f"Training samples: {dataset_sizes['train']}")

def get_model(fine_tune=True):
    # TODO: Load a pre-trained ResNet18
    # model = ...

    # TODO: Freeze parameters if we are NOT fine-tuning (Feature Extraction mode)
    # if not fine_tune:
    #     for param in model.parameters():
    #         param.requires_grad = False

    # TODO: Replace the final Fully Connected layer
    # The new layer should have:
    # in_features = model.fc.in_features
    # out_features = 2 (Ants vs Bees)
    # model.fc = ...

    return model.to(device)

model = get_model(fine_tune=True)

def train_model(model, criterion, optimizer, num_epochs=25):
    since = time.time()

    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # Deep copy the model if it's the best one so far
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc

    print(f'Best val Acc: {best_acc:4f}')
    return model

# Define Loss and Optimizer
criterion = nn.CrossEntropyLoss()

# Note: If fine-tuning, we optimize all params. If feature extraction, only model.fc.parameters()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Start Training
model_ft = train_model(model, criterion, optimizer, num_epochs=10)

"""## Visualize Predictions
Write a small script to grab a batch of validation images, run them through your best model, and display the image with the predicted label vs. the actual label.
"""



"""## Build an Ant/Bee Search Engine üîç
Now that your model has learned to distinguish Ants from Bees, it has learned specific features (wings, legs, thorax shapes) that are unique to these insects.

### Your Goal:
Use your trained model to find images that are visually similar to a query image.

### Steps:

1. Surgery: Remove the final classification layer (model.fc) from your best model. It should now output a 512-dimensional vector (the embedding) instead of 2 class scores.

2. Indexing: Pass the entire Validation Set through this modified model and store the embeddings.

3. Search:

    * Pick a random image from the validation set as your Query.
    * Calculate the Cosine Similarity between your Query and all other images.
    * Display the Query image side-by-side with its Top 3 most similar matches.
"""

